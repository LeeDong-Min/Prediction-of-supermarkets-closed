{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emart = pd.read_excel(\"./prototype_model.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>점포형태</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     점포형태  score\n",
       "0       2   2.71\n",
       "1       2   2.71\n",
       "2       0   2.51\n",
       "3       2   2.51\n",
       "4       2   2.47\n",
       "..    ...    ...\n",
       "142     0   1.27\n",
       "143     0   1.27\n",
       "144     0   1.25\n",
       "145     0   1.21\n",
       "146     0   1.14\n",
       "\n",
       "[147 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = emart.iloc[:,-1]\n",
    "y = emart.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(x).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9387755102040817"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71545718, 0.28454282],\n",
       "       [0.71545718, 0.28454282],\n",
       "       [0.81121719, 0.18878281],\n",
       "       [0.81121719, 0.18878281],\n",
       "       [0.82708663, 0.17291337],\n",
       "       [0.83088519, 0.16911481],\n",
       "       [0.83088519, 0.16911481],\n",
       "       [0.83461698, 0.16538302],\n",
       "       [0.83828245, 0.16171755],\n",
       "       [0.84888581, 0.15111419],\n",
       "       [0.84888581, 0.15111419],\n",
       "       [0.85563252, 0.14436748],\n",
       "       [0.85891095, 0.14108905],\n",
       "       [0.87437952, 0.12562048],\n",
       "       [0.87437952, 0.12562048],\n",
       "       [0.87729328, 0.12270672],\n",
       "       [0.87729328, 0.12270672],\n",
       "       [0.88014872, 0.11985128],\n",
       "       [0.88014872, 0.11985128],\n",
       "       [0.88014872, 0.11985128],\n",
       "       [0.88014872, 0.11985128],\n",
       "       [0.88568761, 0.11431239],\n",
       "       [0.89100222, 0.10899778],\n",
       "       [0.89357734, 0.10642266],\n",
       "       [0.89609873, 0.10390127],\n",
       "       [0.89609873, 0.10390127],\n",
       "       [0.89856715, 0.10143285],\n",
       "       [0.90334831, 0.09665169],\n",
       "       [0.90334831, 0.09665169],\n",
       "       [0.90566264, 0.09433736],\n",
       "       [0.91014279, 0.08985721],\n",
       "       [0.91014279, 0.08985721],\n",
       "       [0.91231021, 0.08768979],\n",
       "       [0.91231021, 0.08768979],\n",
       "       [0.91231021, 0.08768979],\n",
       "       [0.91443027, 0.08556973],\n",
       "       [0.91650377, 0.08349623],\n",
       "       [0.91650377, 0.08349623],\n",
       "       [0.92051425, 0.07948575],\n",
       "       [0.92245283, 0.07754717],\n",
       "       [0.92434801, 0.07565199],\n",
       "       [0.92620057, 0.07379943],\n",
       "       [0.92801131, 0.07198869],\n",
       "       [0.92978098, 0.07021902],\n",
       "       [0.93151037, 0.06848963],\n",
       "       [0.93151037, 0.06848963],\n",
       "       [0.93151037, 0.06848963],\n",
       "       [0.93151037, 0.06848963],\n",
       "       [0.93320022, 0.06679978],\n",
       "       [0.93485129, 0.06514871],\n",
       "       [0.93485129, 0.06514871],\n",
       "       [0.93485129, 0.06514871],\n",
       "       [0.93485129, 0.06514871],\n",
       "       [0.93485129, 0.06514871],\n",
       "       [0.93646434, 0.06353566],\n",
       "       [0.93646434, 0.06353566],\n",
       "       [0.93957928, 0.06042072],\n",
       "       [0.93957928, 0.06042072],\n",
       "       [0.93957928, 0.06042072],\n",
       "       [0.94108264, 0.05891736],\n",
       "       [0.94255088, 0.05744912],\n",
       "       [0.94255088, 0.05744912],\n",
       "       [0.94538482, 0.05461518],\n",
       "       [0.94808667, 0.05191333],\n",
       "       [0.94808667, 0.05191333],\n",
       "       [0.95066183, 0.04933817],\n",
       "       [0.95066183, 0.04933817],\n",
       "       [0.95066183, 0.04933817],\n",
       "       [0.95066183, 0.04933817],\n",
       "       [0.95190355, 0.04809645],\n",
       "       [0.95311556, 0.04688444],\n",
       "       [0.95311556, 0.04688444],\n",
       "       [0.95311556, 0.04688444],\n",
       "       [0.95545299, 0.04454701],\n",
       "       [0.95545299, 0.04454701],\n",
       "       [0.95545299, 0.04454701],\n",
       "       [0.95657964, 0.04342036],\n",
       "       [0.95657964, 0.04342036],\n",
       "       [0.95657964, 0.04342036],\n",
       "       [0.95657964, 0.04342036],\n",
       "       [0.95657964, 0.04342036],\n",
       "       [0.95657964, 0.04342036],\n",
       "       [0.95657964, 0.04342036],\n",
       "       [0.95767905, 0.04232095],\n",
       "       [0.95875183, 0.04124817],\n",
       "       [0.96081981, 0.03918019],\n",
       "       [0.96278813, 0.03721187],\n",
       "       [0.96278813, 0.03721187],\n",
       "       [0.96373631, 0.03626369],\n",
       "       [0.96466121, 0.03533879],\n",
       "       [0.96466121, 0.03533879],\n",
       "       [0.96644329, 0.03355671],\n",
       "       [0.96644329, 0.03355671],\n",
       "       [0.96644329, 0.03355671],\n",
       "       [0.96730149, 0.03269851],\n",
       "       [0.96730149, 0.03269851],\n",
       "       [0.96730149, 0.03269851],\n",
       "       [0.96813847, 0.03186153],\n",
       "       [0.96895471, 0.03104529],\n",
       "       [0.96895471, 0.03104529],\n",
       "       [0.9697507 , 0.0302493 ],\n",
       "       [0.97052689, 0.02947311],\n",
       "       [0.97128376, 0.02871624],\n",
       "       [0.97128376, 0.02871624],\n",
       "       [0.97202176, 0.02797824],\n",
       "       [0.97202176, 0.02797824],\n",
       "       [0.97344288, 0.02655712],\n",
       "       [0.97607747, 0.02392253],\n",
       "       [0.97607747, 0.02392253],\n",
       "       [0.97607747, 0.02392253],\n",
       "       [0.97669522, 0.02330478],\n",
       "       [0.97729739, 0.02270261],\n",
       "       [0.97729739, 0.02270261],\n",
       "       [0.97729739, 0.02270261],\n",
       "       [0.97788436, 0.02211564],\n",
       "       [0.97845648, 0.02154352],\n",
       "       [0.97845648, 0.02154352],\n",
       "       [0.97901412, 0.02098588],\n",
       "       [0.98008735, 0.01991265],\n",
       "       [0.98159708, 0.01840292],\n",
       "       [0.98159708, 0.01840292],\n",
       "       [0.98207492, 0.01792508],\n",
       "       [0.98254057, 0.01745943],\n",
       "       [0.98254057, 0.01745943],\n",
       "       [0.98299433, 0.01700567],\n",
       "       [0.9834365 , 0.0165635 ],\n",
       "       [0.9834365 , 0.0165635 ],\n",
       "       [0.98386736, 0.01613264],\n",
       "       [0.98386736, 0.01613264],\n",
       "       [0.98428719, 0.01571281],\n",
       "       [0.98428719, 0.01571281],\n",
       "       [0.98469627, 0.01530373],\n",
       "       [0.98469627, 0.01530373],\n",
       "       [0.98509486, 0.01490514],\n",
       "       [0.98548322, 0.01451678],\n",
       "       [0.9858616 , 0.0141384 ],\n",
       "       [0.98623027, 0.01376973],\n",
       "       [0.98693938, 0.01306062],\n",
       "       [0.9872803 , 0.0127197 ],\n",
       "       [0.9894327 , 0.0105673 ],\n",
       "       [0.9894327 , 0.0105673 ],\n",
       "       [0.99167822, 0.00832178],\n",
       "       [0.99167822, 0.00832178],\n",
       "       [0.99167822, 0.00832178],\n",
       "       [0.99210902, 0.00789098],\n",
       "       [0.99290534, 0.00709466],\n",
       "       [0.99411156, 0.00588844]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[0.71545718, 0.28454282],\n",
    "       [0.71545718, 0.28454282],\n",
    "       [0.81121719, 0.18878281],\n",
    "       [0.81121719, 0.18878281],\n",
    "       [0.82708663, 0.17291337],\n",
    "       [0.83088519, 0.16911481],\n",
    "       [0.83088519, 0.16911481],\n",
    "       [0.83461698, 0.16538302],\n",
    "       [0.83828245, 0.16171755],\n",
    "       [0.84888581, 0.15111419],\n",
    "       [0.84888581, 0.15111419],\n",
    "       [0.85563252, 0.14436748],\n",
    "       [0.85891095, 0.14108905],\n",
    "       [0.87437952, 0.12562048],\n",
    "       [0.87437952, 0.12562048],\n",
    "       [0.87729328, 0.12270672],\n",
    "       [0.87729328, 0.12270672],\n",
    "       [0.88014872, 0.11985128],\n",
    "       [0.88014872, 0.11985128],\n",
    "       [0.88014872, 0.11985128],\n",
    "       [0.88014872, 0.11985128],\n",
    "       [0.88568761, 0.11431239],\n",
    "       [0.89100222, 0.10899778],\n",
    "       [0.89357734, 0.10642266],\n",
    "       [0.89609873, 0.10390127],\n",
    "       [0.89609873, 0.10390127],\n",
    "       [0.89856715, 0.10143285]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_cv=GridSearchCV(LR,grid,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongmin/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/dongmin/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/dongmin/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/dongmin/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/dongmin/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/dongmin/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/dongmin/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/dongmin/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/dongmin/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/dongmin/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/dongmin/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.496, 0.504],\n",
       "       [0.496, 0.504],\n",
       "       [0.707, 0.293],\n",
       "       [0.707, 0.293],\n",
       "       [0.743, 0.257],\n",
       "       [0.752, 0.248],\n",
       "       [0.752, 0.248],\n",
       "       [0.76 , 0.24 ],\n",
       "       [0.768, 0.232],\n",
       "       [0.791, 0.209],\n",
       "       [0.791, 0.209],\n",
       "       [0.806, 0.194],\n",
       "       [0.813, 0.187],\n",
       "       [0.845, 0.155],\n",
       "       [0.845, 0.155],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.856, 0.144],\n",
       "       [0.856, 0.144],\n",
       "       [0.856, 0.144],\n",
       "       [0.856, 0.144],\n",
       "       [0.867, 0.133],\n",
       "       [0.877, 0.123],\n",
       "       [0.882, 0.118],\n",
       "       [0.886, 0.114],\n",
       "       [0.886, 0.114],\n",
       "       [0.891, 0.109],\n",
       "       [0.899, 0.101],\n",
       "       [0.899, 0.101],\n",
       "       [0.903, 0.097],\n",
       "       [0.911, 0.089],\n",
       "       [0.911, 0.089],\n",
       "       [0.914, 0.086],\n",
       "       [0.914, 0.086],\n",
       "       [0.914, 0.086],\n",
       "       [0.918, 0.082],\n",
       "       [0.921, 0.079],\n",
       "       [0.921, 0.079],\n",
       "       [0.927, 0.073],\n",
       "       [0.93 , 0.07 ],\n",
       "       [0.933, 0.067],\n",
       "       [0.936, 0.064],\n",
       "       [0.939, 0.061],\n",
       "       [0.941, 0.059],\n",
       "       [0.944, 0.056],\n",
       "       [0.944, 0.056],\n",
       "       [0.944, 0.056],\n",
       "       [0.944, 0.056],\n",
       "       [0.946, 0.054],\n",
       "       [0.948, 0.052],\n",
       "       [0.948, 0.052],\n",
       "       [0.948, 0.052],\n",
       "       [0.948, 0.052],\n",
       "       [0.948, 0.052],\n",
       "       [0.95 , 0.05 ],\n",
       "       [0.95 , 0.05 ],\n",
       "       [0.955, 0.045],\n",
       "       [0.955, 0.045],\n",
       "       [0.955, 0.045],\n",
       "       [0.956, 0.044],\n",
       "       [0.958, 0.042],\n",
       "       [0.958, 0.042],\n",
       "       [0.962, 0.038],\n",
       "       [0.965, 0.035],\n",
       "       [0.965, 0.035],\n",
       "       [0.968, 0.032],\n",
       "       [0.968, 0.032],\n",
       "       [0.968, 0.032],\n",
       "       [0.968, 0.032],\n",
       "       [0.969, 0.031],\n",
       "       [0.971, 0.029],\n",
       "       [0.971, 0.029],\n",
       "       [0.971, 0.029],\n",
       "       [0.973, 0.027],\n",
       "       [0.973, 0.027],\n",
       "       [0.973, 0.027],\n",
       "       [0.974, 0.026],\n",
       "       [0.974, 0.026],\n",
       "       [0.974, 0.026],\n",
       "       [0.974, 0.026],\n",
       "       [0.974, 0.026],\n",
       "       [0.974, 0.026],\n",
       "       [0.974, 0.026],\n",
       "       [0.975, 0.025],\n",
       "       [0.976, 0.024],\n",
       "       [0.978, 0.022],\n",
       "       [0.98 , 0.02 ],\n",
       "       [0.98 , 0.02 ],\n",
       "       [0.981, 0.019],\n",
       "       [0.982, 0.018],\n",
       "       [0.982, 0.018],\n",
       "       [0.983, 0.017],\n",
       "       [0.983, 0.017],\n",
       "       [0.983, 0.017],\n",
       "       [0.984, 0.016],\n",
       "       [0.984, 0.016],\n",
       "       [0.984, 0.016],\n",
       "       [0.985, 0.015],\n",
       "       [0.985, 0.015],\n",
       "       [0.985, 0.015],\n",
       "       [0.986, 0.014],\n",
       "       [0.987, 0.013],\n",
       "       [0.987, 0.013],\n",
       "       [0.987, 0.013],\n",
       "       [0.988, 0.012],\n",
       "       [0.988, 0.012],\n",
       "       [0.989, 0.011],\n",
       "       [0.991, 0.009],\n",
       "       [0.991, 0.009],\n",
       "       [0.991, 0.009],\n",
       "       [0.991, 0.009],\n",
       "       [0.991, 0.009],\n",
       "       [0.991, 0.009],\n",
       "       [0.991, 0.009],\n",
       "       [0.992, 0.008],\n",
       "       [0.992, 0.008],\n",
       "       [0.992, 0.008],\n",
       "       [0.993, 0.007],\n",
       "       [0.993, 0.007],\n",
       "       [0.994, 0.006],\n",
       "       [0.994, 0.006],\n",
       "       [0.994, 0.006],\n",
       "       [0.995, 0.005],\n",
       "       [0.995, 0.005],\n",
       "       [0.995, 0.005],\n",
       "       [0.995, 0.005],\n",
       "       [0.995, 0.005],\n",
       "       [0.995, 0.005],\n",
       "       [0.995, 0.005],\n",
       "       [0.995, 0.005],\n",
       "       [0.995, 0.005],\n",
       "       [0.996, 0.004],\n",
       "       [0.996, 0.004],\n",
       "       [0.996, 0.004],\n",
       "       [0.996, 0.004],\n",
       "       [0.996, 0.004],\n",
       "       [0.996, 0.004],\n",
       "       [0.997, 0.003],\n",
       "       [0.997, 0.003],\n",
       "       [0.998, 0.002],\n",
       "       [0.998, 0.002],\n",
       "       [0.998, 0.002],\n",
       "       [0.998, 0.002],\n",
       "       [0.998, 0.002],\n",
       "       [0.999, 0.001],\n",
       "       [0.999, 0.001],\n",
       "       [0.999, 0.001]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(logreg_cv.predict_proba(X),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
